import streamlit as st
import pandas as pd
import numpy as np
import io

# --- 1. CONFIGURATION: DEFINE YOUR VALIDATION RULES HERE ---

# List of columns to check for straightlining (Likert scales)
GRID_COLUMNS = [f'Q5_{i}' for i in range(1, 6)] 

# List of all Skip Logic rules
# **IMPORTANT:** Update these rules to match your actual survey logic columns and values
SKIP_LOGIC_RULES = [
    {
        "check_id": "SL_001_CarBrand",
        "target": "Q2_Brand",       # Question that should be skipped
        "trigger_col": "Q1_OwnCar",  # Question that controls the skip
        "trigger_val": 1             # Value required in Q1 to ask Q2 (e.g., 1=Yes)
    },
    {
        "check_id": "SL_002_PetFood",
        "target": "Q4_PetFood",
        "trigger_col": "Q3_OwnPet",
        "trigger_val": 1
    }
]

# List of expected critical columns (for a basic check)
CRITICAL_COLUMNS = ['uuid', 'Duration_Seconds', 'Q1_OwnCar', 'Q2_Brand', 'Q3_OwnPet', 'Q4_PetFood']

# --- 2. CORE VALIDATION LOGIC FUNCTIONS ---

def run_validation(df):
    """Applies all validation checks and creates flag columns."""
    
    # Ensure UUID exists and convert to string
    if 'uuid' not in df.columns:
        df['uuid'] = df.index
    df['uuid'] = df['uuid'].astype(str)

    # --- Speeder Check ---
    if 'Duration_Seconds' in df.columns:
        median_time = df['Duration_Seconds'].median()
        threshold = median_time * 0.4  # Flag if faster than 40% of median
        df['Flag_Speeder'] = np.where(df['Duration_Seconds'] < threshold, 1, 0)
    else:
        st.warning("Column 'Duration_Seconds' not found. Skipping Speeder Check.")
        df['Flag_Speeder'] = 0

    # --- Straightliner Check ---
    if all(col in df.columns for col in GRID_COLUMNS):
        # Calculate standard deviation across the grid columns for each respondent
        df['grid_std'] = df[GRID_COLUMNS].std(axis=1)
        # Flag 1 if the standard deviation is 0 (all answers are the same)
        df['Flag_StraightLine'] = np.where(df['grid_std'] == 0, 1, 0)
    else:
        st.warning(f"One or more grid columns {GRID_COLUMNS} not found. Skipping Straightliner Check.")
        df['Flag_StraightLine'] = 0

    # --- Skip Logic Checks ---
    for rule in SKIP_LOGIC_RULES:
        if all(col in df.columns for col in [rule['target'], rule['trigger_col']]):
            flag_col = f"Flag_{rule['check_id']}"
            
            # Error of Commission (Shouldn't have answered, but did)
            # e.g., Q1 != 1 AND Q2 is NOT NULL
            commission_mask = (df[rule['trigger_col']] != rule['trigger_val']) & (df[rule['target']].notna())
            
            # Error of Omission (Should have answered, but didn't)
            # e.g., Q1 = 1 AND Q2 is NULL
            omission_mask = (df[rule['trigger_col']] == rule['trigger_val']) & (df[rule['target']].isna())
            
            # Flag 1 if EITHER error type occurred
            df[flag_col] = np.where(commission_mask | omission_mask, 1, 0)
        else:
            st.warning(f"Columns for rule {rule['check_id']} not found. Skipping rule.")

    # Compile the final list of all flag columns generated
    flag_columns = [col for col in df.columns if col.startswith('Flag_')]
    
    return df, flag_columns

def generate_spss_syntax(df, flag_cols):
    """Generates the .sps file content as a string."""
    
    sps_content = []
    
    sps_content.append(f"*{'='*60}*")
    sps_content.append(f"* SPSS SYNTAX GENERATED BY PYTHON VALIDATION SCRIPT *")
    sps_content.append(f"*{'='*60}*\n")
    sps_content.append("DATASET ACTIVATE ALL.")
    
    # 1. Define the new flag variables and labels
    sps_content.append("\n* --- 1. VARIABLE DEFINITION (Labels/Values) --- *")
    for flag in flag_cols:
        label = flag.replace('Flag_', '')
        sps_content.append(f"VARIABLE LABELS {flag} '{label} Validation Check'.")
        sps_content.append(f"VALUE LABELS {flag} 0 'Pass' 1 'Fail'.")
        sps_content.append(f"FORMATS {flag} (F8.0).")
    sps_content.append("EXECUTE.")

    # 2. Compute a Master Reject Flag
    sps_content.append("\n* --- 2. COMPUTE MASTER REJECT FLAG --- *")
    master_flag_logic = ' + '.join(flag_cols)
    sps_content.append(f"COMPUTE Master_Reject_Count = SUM({master_flag_logic}).")
    sps_content.append("VARIABLE LABELS Master_Reject_Count 'Total Number of Validation Errors'.")
    sps_content.append("EXECUTE.")
    
    # 3. Core Validation Output (Frequencies)
    sps_content.append("\n* --- 3. VALIDATION REPORT (Frequencies) --- *")
    sps_content.append(f"FREQUENCIES VARIABLES={'; '.join(flag_cols)}.")

    # 4. Filter for Manual Review (Selecting the rejected cases)
    sps_content.append("\n* --- 4. FILTER CASES WITH ERRORS FOR REVIEW --- *")
    sps_content.append("DATASET DECLARE Rejected_Cases.")
    sps_content.append("SELECT IF (Master_Reject_Count > 0).")
    sps_content.append("EXECUTE.")
    sps_content.append("DATASET NAME Rejected_Cases WINDOW=FRONT.")
    sps_content.append("\n* The active dataset is now filtered to show only errors for manual checking. *")
    spss_syntax = '\n'.join(sps_content)
    
    return spss_syntax

def generate_excel_report(df, flag_cols):
    """Generates the Excel error report as bytes."""
    
    # Create a summary column showing how many errors each respondent has
    df['Total_Errors'] = df[flag_cols].sum(axis=1)

    # Filter down to only the rows that have one or more errors
    error_df = df[df['Total_Errors'] > 0]
    
    # Select only key identification columns and the flag columns for the report
    cols_to_report = [col for col in df.columns if col in CRITICAL_COLUMNS] + flag_cols + ['Total_Errors']
    report_df = error_df[cols_to_report]
    
    # Use io.BytesIO to write the Excel file in memory
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        if not report_df.empty:
            report_df.to_excel(writer, sheet_name='Respondent Errors', index=False)
        else:
            # If no errors, provide a status sheet
            status_df = pd.DataFrame([["Validation completed successfully. No errors detected."]], columns=['Status'])
            status_df.to_excel(writer, sheet_name='Validation Status', index=False)
            
    processed_data = output.getvalue()
    return processed_data

# --- 3. STREAMLIT APPLICATION LAYOUT ---

st.title("üìä Automated Survey Data Validation")
st.markdown("Upload your raw survey data (CSV) to run Python-based validation, generate SPSS syntax, and an Excel error report.")

uploaded_file = st.file_uploader("Choose a CSV File", type="csv")

if uploaded_file is not None:
    try:
        # Load the data
        df_raw = pd.read_csv(uploaded_file, encoding='latin-1')
        
        st.subheader("1. Data Ingestion Successful")
        st.write(f"Loaded {len(df_raw)} rows and {len(df_raw.columns)} columns.")
        
        # --- Run Validation ---
        with st.spinner("Running Python validation checks..."):
            df_validated, flag_columns = run_validation(df_raw.copy())
            
        st.subheader("2. Validation Complete")
        st.success(f"Generated {len(flag_columns)} flag columns.")
        
        # Calculate error stats
        error_count = df_validated['Total_Errors'].fillna(0).astype(bool).sum()
        total_respondents = len(df_validated)
        st.metric("Respondents with Errors", error_count, delta=f"{(error_count/total_respondents)*100:.2f}% of total")
        
        # --- Generate Outputs ---
        
        spss_syntax = generate_spss_syntax(df_validated, flag_columns)
        excel_report_bytes = generate_excel_report(df_validated, flag_columns)
        
        st.subheader("3. Download Results")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.download_button(
                label="‚¨áÔ∏è Download SPSS Syntax (.sps)",
                data=spss_syntax,
                file_name="validation_flags_syntax.sps",
                mime="text/plain"
            )
            st.caption("Run this file in SPSS to define the flag variables and generate frequency reports.")
            
        with col2:
            st.download_button(
                label="‚¨áÔ∏è Download Excel Error Report (.xlsx)",
                data=excel_report_bytes,
                file_name="validation_error_report.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
            st.caption("Contains only respondents with errors for quick manual review.")
            
        st.markdown("---")
        st.markdown("**Instructions:** Download both files. Run the `.sps` file in SPSS first, then open your raw data and apply the filter based on the generated `Master_Reject_Count` variable.")

    except Exception as e:
        st.error(f"An error occurred during processing. Please check your data format: {e}")

# --- End of Streamlit Script ---